{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The Classifier\n",
    "\n",
    "This notebook is for building the classifier to analyze the tweets from 2011 and 2019. I found a dataset of tweets called [Sentiment140](http://help.sentiment140.com/for-students) that had already been given a positive and negative ranking based on which emoticons the tweet used. I decided to use that as a starting off point for building my classifier. \n",
    "\n",
    "First I import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "# Formatting\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening the dataset and putting it into a dataframe and annotated the columns based on what the Sentiment140 site had said. I am most interested in polarity (0 for negative and 4 for positive) and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building classifier\n",
    "f = open(r'D:\\Documents\\Classes\\Spring2020\\ling1340\\Twitter-Positivity-Analysis\\data\\trainingandtestdata\\training.1600000.processed.noemoticon.csv', 'r+')\n",
    "classify = pd.read_csv(f, index_col=False, names=[\"polarity\", \"tweet_id\", \"date\", \"query\", \"username\", \"text\"] ,error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a huge corpus, over 1500000 entries! I spent a lot of time trying to work with the entire corpus which caused me a LOT of problems trying to compile. For the sake of time and resources I decided to pare down the corpus to about 1/4 the size.\n",
    "\n",
    "I first shuffled the dataset, as the entries were ordered by polarity. Then I took the first 200,000 entries and put them in `classifysm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>608693</td>\n",
       "      <td>0</td>\n",
       "      <td>2223442081</td>\n",
       "      <td>Thu Jun 18 08:16:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ambick</td>\n",
       "      <td>My poor son is being circumcised right now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1463003</td>\n",
       "      <td>4</td>\n",
       "      <td>2064087901</td>\n",
       "      <td>Sun Jun 07 05:10:51 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>gemcruz</td>\n",
       "      <td>@mulder8scully5 hi pet!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>978725</td>\n",
       "      <td>4</td>\n",
       "      <td>1833860922</td>\n",
       "      <td>Mon May 18 00:43:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ShelleAmanda</td>\n",
       "      <td>@ddlovato Demi.. Don't say that! you are soo w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>911725</td>\n",
       "      <td>4</td>\n",
       "      <td>1752051769</td>\n",
       "      <td>Sat May 09 20:56:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>benlawsonphoto</td>\n",
       "      <td>@NicholeAudrey LOL! Ok, &amp;quot;we&amp;quot; will ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255843</td>\n",
       "      <td>0</td>\n",
       "      <td>1984584311</td>\n",
       "      <td>Sun May 31 15:23:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>MGHarris</td>\n",
       "      <td>@casshorowitz good luck. I totally failed to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>914768</td>\n",
       "      <td>4</td>\n",
       "      <td>1752943543</td>\n",
       "      <td>Sat May 09 23:32:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ThankYouProject</td>\n",
       "      <td>@ggw_bach Thank you for YOUR positive energy +...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1421569</td>\n",
       "      <td>4</td>\n",
       "      <td>2058347713</td>\n",
       "      <td>Sat Jun 06 14:45:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>iamdebra</td>\n",
       "      <td>@BethRosen Thanks.  I'm going to see if I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1003629</td>\n",
       "      <td>4</td>\n",
       "      <td>1880334713</td>\n",
       "      <td>Fri May 22 00:52:42 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Livedreams9</td>\n",
       "      <td>@billyraycyrus Tweet dreams :] Tweep tight :] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1051607</td>\n",
       "      <td>4</td>\n",
       "      <td>1961195251</td>\n",
       "      <td>Fri May 29 09:07:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>santaaurelia</td>\n",
       "      <td>@safirathetiger thanks for follow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1473579</td>\n",
       "      <td>4</td>\n",
       "      <td>2065576124</td>\n",
       "      <td>Sun Jun 07 08:52:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>haleyymae</td>\n",
       "      <td>@myria101 I am now</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity    tweet_id                          date     query  \\\n",
       "608693          0  2223442081  Thu Jun 18 08:16:44 PDT 2009  NO_QUERY   \n",
       "1463003         4  2064087901  Sun Jun 07 05:10:51 PDT 2009  NO_QUERY   \n",
       "978725          4  1833860922  Mon May 18 00:43:13 PDT 2009  NO_QUERY   \n",
       "911725          4  1752051769  Sat May 09 20:56:07 PDT 2009  NO_QUERY   \n",
       "255843          0  1984584311  Sun May 31 15:23:48 PDT 2009  NO_QUERY   \n",
       "914768          4  1752943543  Sat May 09 23:32:12 PDT 2009  NO_QUERY   \n",
       "1421569         4  2058347713  Sat Jun 06 14:45:31 PDT 2009  NO_QUERY   \n",
       "1003629         4  1880334713  Fri May 22 00:52:42 PDT 2009  NO_QUERY   \n",
       "1051607         4  1961195251  Fri May 29 09:07:40 PDT 2009  NO_QUERY   \n",
       "1473579         4  2065576124  Sun Jun 07 08:52:43 PDT 2009  NO_QUERY   \n",
       "\n",
       "                username                                               text  \n",
       "608693            ambick        My poor son is being circumcised right now   \n",
       "1463003          gemcruz                         @mulder8scully5 hi pet!!!   \n",
       "978725      ShelleAmanda  @ddlovato Demi.. Don't say that! you are soo w...  \n",
       "911725    benlawsonphoto  @NicholeAudrey LOL! Ok, &quot;we&quot; will ge...  \n",
       "255843          MGHarris  @casshorowitz good luck. I totally failed to i...  \n",
       "914768   ThankYouProject  @ggw_bach Thank you for YOUR positive energy +...  \n",
       "1421569         iamdebra  @BethRosen Thanks.  I'm going to see if I can ...  \n",
       "1003629      Livedreams9  @billyraycyrus Tweet dreams :] Tweep tight :] ...  \n",
       "1051607     santaaurelia                 @safirathetiger thanks for follow   \n",
       "1473579        haleyymae                                @myria101 I am now   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "classify = shuffle(classify)\n",
    "classify[:10]\n",
    "classifysm = classify[:200000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I sorted the dataframe into positive and negative tweets. I did this because I thought it might be useful and so that i could manipulate either polarity easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1463003</td>\n",
       "      <td>4</td>\n",
       "      <td>2064087901</td>\n",
       "      <td>Sun Jun 07 05:10:51 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>gemcruz</td>\n",
       "      <td>@mulder8scully5 hi pet!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>978725</td>\n",
       "      <td>4</td>\n",
       "      <td>1833860922</td>\n",
       "      <td>Mon May 18 00:43:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ShelleAmanda</td>\n",
       "      <td>@ddlovato Demi.. Don't say that! you are soo w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>911725</td>\n",
       "      <td>4</td>\n",
       "      <td>1752051769</td>\n",
       "      <td>Sat May 09 20:56:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>benlawsonphoto</td>\n",
       "      <td>@NicholeAudrey LOL! Ok, &amp;quot;we&amp;quot; will ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>914768</td>\n",
       "      <td>4</td>\n",
       "      <td>1752943543</td>\n",
       "      <td>Sat May 09 23:32:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ThankYouProject</td>\n",
       "      <td>@ggw_bach Thank you for YOUR positive energy +...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1421569</td>\n",
       "      <td>4</td>\n",
       "      <td>2058347713</td>\n",
       "      <td>Sat Jun 06 14:45:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>iamdebra</td>\n",
       "      <td>@BethRosen Thanks.  I'm going to see if I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390508</td>\n",
       "      <td>4</td>\n",
       "      <td>2053224846</td>\n",
       "      <td>Sat Jun 06 03:45:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jetdillo</td>\n",
       "      <td>errr...should have said &amp;quot;Leaving for RIC&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893693</td>\n",
       "      <td>4</td>\n",
       "      <td>1691979600</td>\n",
       "      <td>Sun May 03 19:01:15 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>StephParrott</td>\n",
       "      <td>Sitting here talking to my boyfriend who just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>824434</td>\n",
       "      <td>4</td>\n",
       "      <td>1556242184</td>\n",
       "      <td>Sat Apr 18 22:07:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>cyberfx1</td>\n",
       "      <td>@ShannonLeto Awwww....you made me SMILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895955</td>\n",
       "      <td>4</td>\n",
       "      <td>1692855543</td>\n",
       "      <td>Sun May 03 20:56:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sonjaphelps</td>\n",
       "      <td>has just hung with Drew in FL ~ great friends ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1387959</td>\n",
       "      <td>4</td>\n",
       "      <td>2052983054</td>\n",
       "      <td>Sat Jun 06 02:48:19 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Lilemzys</td>\n",
       "      <td>Going to buy ingredients for a yummy stew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99985 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity    tweet_id                          date     query  \\\n",
       "1463003         4  2064087901  Sun Jun 07 05:10:51 PDT 2009  NO_QUERY   \n",
       "978725          4  1833860922  Mon May 18 00:43:13 PDT 2009  NO_QUERY   \n",
       "911725          4  1752051769  Sat May 09 20:56:07 PDT 2009  NO_QUERY   \n",
       "914768          4  1752943543  Sat May 09 23:32:12 PDT 2009  NO_QUERY   \n",
       "1421569         4  2058347713  Sat Jun 06 14:45:31 PDT 2009  NO_QUERY   \n",
       "...           ...         ...                           ...       ...   \n",
       "1390508         4  2053224846  Sat Jun 06 03:45:54 PDT 2009  NO_QUERY   \n",
       "893693          4  1691979600  Sun May 03 19:01:15 PDT 2009  NO_QUERY   \n",
       "824434          4  1556242184  Sat Apr 18 22:07:14 PDT 2009  NO_QUERY   \n",
       "895955          4  1692855543  Sun May 03 20:56:52 PDT 2009  NO_QUERY   \n",
       "1387959         4  2052983054  Sat Jun 06 02:48:19 PDT 2009  NO_QUERY   \n",
       "\n",
       "                username                                               text  \n",
       "1463003          gemcruz                         @mulder8scully5 hi pet!!!   \n",
       "978725      ShelleAmanda  @ddlovato Demi.. Don't say that! you are soo w...  \n",
       "911725    benlawsonphoto  @NicholeAudrey LOL! Ok, &quot;we&quot; will ge...  \n",
       "914768   ThankYouProject  @ggw_bach Thank you for YOUR positive energy +...  \n",
       "1421569         iamdebra  @BethRosen Thanks.  I'm going to see if I can ...  \n",
       "...                  ...                                                ...  \n",
       "1390508         jetdillo  errr...should have said &quot;Leaving for RIC&...  \n",
       "893693      StephParrott  Sitting here talking to my boyfriend who just ...  \n",
       "824434          cyberfx1           @ShannonLeto Awwww....you made me SMILE   \n",
       "895955       sonjaphelps  has just hung with Drew in FL ~ great friends ...  \n",
       "1387959         Lilemzys         Going to buy ingredients for a yummy stew   \n",
       "\n",
       "[99985 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>608693</td>\n",
       "      <td>0</td>\n",
       "      <td>2223442081</td>\n",
       "      <td>Thu Jun 18 08:16:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ambick</td>\n",
       "      <td>My poor son is being circumcised right now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255843</td>\n",
       "      <td>0</td>\n",
       "      <td>1984584311</td>\n",
       "      <td>Sun May 31 15:23:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>MGHarris</td>\n",
       "      <td>@casshorowitz good luck. I totally failed to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400617</td>\n",
       "      <td>0</td>\n",
       "      <td>2057455901</td>\n",
       "      <td>Sat Jun 06 13:02:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Brittneyondich</td>\n",
       "      <td>Grad party and then a soriee. I wish I was at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309062</td>\n",
       "      <td>0</td>\n",
       "      <td>2000826995</td>\n",
       "      <td>Mon Jun 01 23:04:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>supergirlnancy</td>\n",
       "      <td>twitter wont let me upload a new pic ???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146776</td>\n",
       "      <td>0</td>\n",
       "      <td>1882577611</td>\n",
       "      <td>Fri May 22 07:07:17 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ShakilaKelley</td>\n",
       "      <td>sp proud of the mr. a lil disappointed that i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168678</td>\n",
       "      <td>0</td>\n",
       "      <td>1962256864</td>\n",
       "      <td>Fri May 29 10:46:01 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>purity_xo</td>\n",
       "      <td>@reactiveretro yeah i agree, he was the best! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211840</td>\n",
       "      <td>0</td>\n",
       "      <td>1974589898</td>\n",
       "      <td>Sat May 30 13:26:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bobbi10100</td>\n",
       "      <td>@TessMorris Poor you   Hope it doesn't last lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135109</td>\n",
       "      <td>0</td>\n",
       "      <td>1836430771</td>\n",
       "      <td>Mon May 18 07:59:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Torontonian_Fan</td>\n",
       "      <td>@sofdlovesbsb i wish i had gone  wouldnt it ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>667563</td>\n",
       "      <td>0</td>\n",
       "      <td>2245648277</td>\n",
       "      <td>Fri Jun 19 16:26:15 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>kangaroo5383</td>\n",
       "      <td>goodbye t-mobile, you've been good to me all t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>757198</td>\n",
       "      <td>0</td>\n",
       "      <td>2295233964</td>\n",
       "      <td>Tue Jun 23 07:39:39 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>omgthatschelle</td>\n",
       "      <td>@goldabayle I went to check my marks, but they...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100015 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        polarity    tweet_id                          date     query  \\\n",
       "608693         0  2223442081  Thu Jun 18 08:16:44 PDT 2009  NO_QUERY   \n",
       "255843         0  1984584311  Sun May 31 15:23:48 PDT 2009  NO_QUERY   \n",
       "400617         0  2057455901  Sat Jun 06 13:02:18 PDT 2009  NO_QUERY   \n",
       "309062         0  2000826995  Mon Jun 01 23:04:09 PDT 2009  NO_QUERY   \n",
       "146776         0  1882577611  Fri May 22 07:07:17 PDT 2009  NO_QUERY   \n",
       "...          ...         ...                           ...       ...   \n",
       "168678         0  1962256864  Fri May 29 10:46:01 PDT 2009  NO_QUERY   \n",
       "211840         0  1974589898  Sat May 30 13:26:40 PDT 2009  NO_QUERY   \n",
       "135109         0  1836430771  Mon May 18 07:59:13 PDT 2009  NO_QUERY   \n",
       "667563         0  2245648277  Fri Jun 19 16:26:15 PDT 2009  NO_QUERY   \n",
       "757198         0  2295233964  Tue Jun 23 07:39:39 PDT 2009  NO_QUERY   \n",
       "\n",
       "               username                                               text  \n",
       "608693           ambick        My poor son is being circumcised right now   \n",
       "255843         MGHarris  @casshorowitz good luck. I totally failed to i...  \n",
       "400617   Brittneyondich  Grad party and then a soriee. I wish I was at ...  \n",
       "309062   supergirlnancy          twitter wont let me upload a new pic ???   \n",
       "146776    ShakilaKelley  sp proud of the mr. a lil disappointed that i ...  \n",
       "...                 ...                                                ...  \n",
       "168678        purity_xo  @reactiveretro yeah i agree, he was the best! ...  \n",
       "211840       bobbi10100  @TessMorris Poor you   Hope it doesn't last lo...  \n",
       "135109  Torontonian_Fan  @sofdlovesbsb i wish i had gone  wouldnt it ha...  \n",
       "667563     kangaroo5383  goodbye t-mobile, you've been good to me all t...  \n",
       "757198   omgthatschelle  @goldabayle I went to check my marks, but they...  \n",
       "\n",
       "[100015 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tweets = pd.DataFrame()\n",
    "pos_tweets = classifysm[classifysm['polarity'] == 4]\n",
    "pos_tweets\n",
    "\n",
    "neg_tweets = pd.DataFrame()\n",
    "neg_tweets = classifysm[classifysm['polarity'] == 0]\n",
    "neg_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I cleaned the text column and took out things like usernames, hashtags, and other symbols. I word tokenized the cleaned list and normalized all the words to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = []\n",
    "neg_list= []\n",
    "pos_list = ([re.sub(r'(?:(@|&|;|http|https)[\\w_]+)', '', i) for i in pos_tweets['text']])\n",
    "neg_list = ([re.sub(r'(?:(@|&|;|http|https)[\\w_]+)', '', i) for i in neg_tweets['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "pos_toks = [word_tokenize(i) for i in pos_list]\n",
    "neg_toks = [word_tokenize(i) for i in neg_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "poslower = []\n",
    "for line in pos_toks:\n",
    "    poslower.append([w.lower() for w in line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "neglower = []\n",
    "for line in neg_toks:\n",
    "    neglower.append([w.lower() for w in line])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then took the tokenized words and started to build a simple Naive Bayers classifier based on chapter 6 of the nltk book for [this](https://www.nltk.org/book/ch06.html) movie reviews classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "posneglower = poslower+neglower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "all_words = [nltk.FreqDist(posneglower[0])]\n",
    "while True:\n",
    "    all_words = nltk.FreqDist(posneglower[i])\n",
    "    if i > len(posneglower)-2:\n",
    "        break\n",
    "    i = i+1\n",
    "word_features = list(all_words)[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['o', '...', '..k', '...', '.', 'that', 'looks', 'like', 'a', 'really', 'wierd', 'show', ':', 's', '...', '.', 'i', 'ca', \"n't\", 'watch', 'a', 'show', 'without', 'plot', 'lines'], 4), (['i', 'knoww', ',', 'so', 'excitedd', 'we', \"'ll\", 'need', 'to', 'have', 'a', 'major', 'catch-up', 'before', 'we', 'get', 'the', 'bus', 'ca', \"n't\", 'wait', 'to', 'see', 'you', '!', 'xx'], 4), (['baby', 'shower', 'today', '...', 'and', 'not', 'of', 'the', '4-legged', 'variety'], 0), (['seriously', '!', 'i', 'know', 'this', 'cuz', 'i', 'have', 'a', 'gay', 'friend', 'lol', 'i', \"'m\", 'trying', 'to', 'cheer', 'up', 'bb..', 'it', 'ai', \"n't\", 'easy', 'though'], 0), (['you', \"'re\", 'probably', 'not', 'but', 'you', \"'re\", 'only', 'one', 'i', 'know', 'that', 'dances', 'in', 'there', 'undies', 'on', 'twitter', 'lol'], 4)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a tuple of the tweet tokens and the polarity ranking\n",
    "pos_tup = [(x,4) for x in poslower]\n",
    "neg_tup = [(x,0) for x in neglower]\n",
    "posng_tup = pos_tup+neg_tup\n",
    "\n",
    "from random import shuffle\n",
    "shuffle(posng_tup)\n",
    "posng_tup[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in posng_tup]\n",
    "#90/10 split to the data\n",
    "train_set, test_set = featuresets[20000:], featuresets[:20000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5888"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "         contains(check) = True                4 : 0      =      3.0 : 1.0\n",
      "           contains(n't) = True                0 : 4      =      2.2 : 1.0\n",
      "         contains(marks) = True                0 : 4      =      2.1 : 1.0\n",
      "           contains(but) = True                0 : 4      =      1.7 : 1.0\n",
      "          contains(went) = True                0 : 4      =      1.5 : 1.0\n",
      "            contains(my) = True                0 : 4      =      1.5 : 1.0\n",
      "             contains(i) = True                0 : 4      =      1.4 : 1.0\n",
      "          contains(they) = True                0 : 4      =      1.4 : 1.0\n",
      "             contains(i) = False               4 : 0      =      1.3 : 1.0\n",
      "          contains(were) = True                0 : 4      =      1.2 : 1.0\n",
      "            contains(to) = True                0 : 4      =      1.2 : 1.0\n",
      "         contains(there) = True                0 : 4      =      1.2 : 1.0\n",
      "             contains(,) = True                4 : 0      =      1.1 : 1.0\n",
      "           contains(n't) = False               4 : 0      =      1.1 : 1.0\n",
      "            contains(my) = False               4 : 0      =      1.1 : 1.0\n",
      "            contains(to) = False               4 : 0      =      1.1 : 1.0\n",
      "           contains(but) = False               4 : 0      =      1.0 : 1.0\n",
      "             contains(,) = False               0 : 4      =      1.0 : 1.0\n",
      "          contains(they) = False               4 : 0      =      1.0 : 1.0\n",
      "         contains(check) = False               0 : 4      =      1.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I admit this is not the best result, but I spent so long fiddling with the data that unfortuately most of my time went into that. \n",
    "\n",
    "Moving forward I want to clean up the test data in a way that improves accuracy, and also look into a classifier better suited to this dataset. For now, i'm going to move forward with this less-than-ideal classifier and describe the kinds of things I would look into with a better classifier in the future. I'm just going to pickle a few important things so I can use them back in [this notebook](https://github.com/Data-Science-for-Linguists-2020/Twitter-Positivity-Analysis/blob/master/notebooks/data_analysis.ipynb). See you there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open( \"classifier.pkl\", \"wb\" )\n",
    "pickle.dump(classifier, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open( \"word_features.pkl\", \"wb\" )\n",
    "pickle.dump(word_features, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
